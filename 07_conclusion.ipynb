{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- Overview von Scores der verschiedenen Modelle\n",
    "    - Barplots\n",
    "    - Tabelle in 5_Notebooks wo wir abespeichern Scores und Modellname, Dictionary oder Pandas df?\n",
    "- Feature Importance Vergleichen\n",
    "    - Graphiken exportieren in Modell Notebooks und hier nebeneinander darstellen\n",
    "    - Top 3 Feature nennen, sonstige Auff채lligkeiten\n",
    "- Fehlerauswertung, systematische Fehler?\n",
    "- Empfehlung f체r Modell aussprechen anhand eines Use Cases\n",
    "    - Vorteil Logistic ist dass es tunable vor Use Case\n",
    "    - Vorteil decision tree ist dass es genauer ist und White box\n",
    "    - ?? Ist catboost wirklich besser in diesem Fall?? Sonst reicht auch Decision tree vermutlich\n",
    "- Pr체fen: Farbreihenfolge Fehleranalyse Kategorische Variablen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- in notebooks mehr beschreiben\n",
    "- Scores innerhalb von 05 besser erkl채ren/ interpretieren/ wie zufrieden mit dem Wert?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do (from data cleaning)\n",
    "\n",
    "### features to be further examined:\n",
    "- 'feedback' group by positive and negative feedback\n",
    "\n",
    "Next steps/second iteration:\n",
    "- https://annahava.medium.com/too-many-categories-how-to-deal-with-categorical-features-of-high-cardinality-d4563cfe62d6\n",
    "- https://www.datacamp.com/tutorial/categorical-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explain threshold and scores from Logist Regression"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
